{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73aa4de5-73c7-45fe-8e0c-c8dd7be1f675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.local/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./.local/lib/python3.10/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.13.4)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in ./.local/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.local/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9727ee2c-13f8-449a-8d71-f5c5d996e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.local/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.local/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.local/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.local/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.local/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.local/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.local/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.25.0)\n",
      "Requirement already satisfied: lit in ./.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d9e0f3-a90a-4836-8da0-89366c200982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.28.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243dc8dc-fe66-496b-bf6b-a6ce30e28483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kobart\n",
      "  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-install-vk419a8b/kobart_b3b183bce16e427482f5cc981d4f98bd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKT-AI/KoBART /tmp/pip-install-vk419a8b/kobart_b3b183bce16e427482f5cc981d4f98bd\n",
      "  Resolved https://github.com/SKT-AI/KoBART to commit 30c5eb7b593828d6ec2d767eeedb2f2ed02c5c2a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting boto3 (from kobart)\n",
      "  Using cached boto3-1.26.120-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from kobart) (1.5.3)\n",
      "Collecting pytorch-lightning==1.2.1 (from kobart)\n",
      "  Using cached pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
      "INFO: pip is looking at multiple versions of kobart to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from kobart) (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/SKT-AI/KoBART#egg=kobart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b81e92c-a319-4c71-9322-afbcc73b8321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext==0.8.0 (from versions: 0.1.1, 0.2.0, 0.2.1, 0.2.3, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext==0.8.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc04f3bb-9a88-4b88-9cee-9533e8d109eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyyaml==5.4.1 in ./.local/lib/python3.10/site-packages (5.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml==5.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e953de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 텍스트 파일로 저장\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c3eb37-39ae-413f-8cfc-1f090bb8701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REPORT-news_r-00001-00001</td>\n",
       "      <td>40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.\\n  4...</td>\n",
       "      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REPORT-news_r-00005-00001</td>\n",
       "      <td>시진핑 방한과 새해 한·중관계 전망지난달 23일 베이징에서 열린 한·중 정상회담을 ...</td>\n",
       "      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REPORT-news_r-00005-00003</td>\n",
       "      <td>한·중이 사드에 관한 ‘3불(不)’이 ‘약속’인지 ‘입장표명’인지 표현을 놓고 갈...</td>\n",
       "      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REPORT-news_r-00009-00001</td>\n",
       "      <td>배달의민족이 독일 자본에 매각된 것을 놓고 말들이 많다.\\n  민족 정서를 배반했다...</td>\n",
       "      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REPORT-news_r-00012-00001</td>\n",
       "      <td>지난 28일부터 나흘간 진행된 7기 5차 노동당 전원회의에서 북한은 핵 무력 개발의...</td>\n",
       "      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Id  \\\n",
       "0  REPORT-news_r-00001-00001   \n",
       "1  REPORT-news_r-00005-00001   \n",
       "2  REPORT-news_r-00005-00003   \n",
       "3  REPORT-news_r-00009-00001   \n",
       "4  REPORT-news_r-00012-00001   \n",
       "\n",
       "                                              source  \\\n",
       "0  40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.\\n  4...   \n",
       "1  시진핑 방한과 새해 한·중관계 전망지난달 23일 베이징에서 열린 한·중 정상회담을 ...   \n",
       "2   한·중이 사드에 관한 ‘3불(不)’이 ‘약속’인지 ‘입장표명’인지 표현을 놓고 갈...   \n",
       "3  배달의민족이 독일 자본에 매각된 것을 놓고 말들이 많다.\\n  민족 정서를 배반했다...   \n",
       "4  지난 28일부터 나흘간 진행된 7기 5차 노동당 전원회의에서 북한은 핵 무력 개발의...   \n",
       "\n",
       "                                              target  \n",
       "0  DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...  \n",
       "1  한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...  \n",
       "2  사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...  \n",
       "3  배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...  \n",
       "4  북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c15da5-87b2-4429-ad4f-25e8b1e4845f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REPORT-news_r-00014-00001</td>\n",
       "      <td>일본 사법당국의 출국금지 명령이 내려져 있던 카를로스 곤(65) 전 르노닛산 회장이...</td>\n",
       "      <td>출국금지 명령을 받은 곤 전 르노닛산 회장이 레바논으로 도주하며 일본의 정치적 박해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REPORT-news_r-00035-00001</td>\n",
       "      <td>황교안 자유한국당 대표의 최측근인 김도읍 의원(재선)이 느닷없이 불출마를 선언하자 ...</td>\n",
       "      <td>황 대표는 김 의원의 불출마 소식을 알았다면 말릴 걸 알고 미리 말 안 한 것 같다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REPORT-news_r-00042-00003</td>\n",
       "      <td>추울수록 위력이 강할 듯했다.\\n   통영의 하루를 여는 음식이 시락국이라면 ‘우...</td>\n",
       "      <td>통영에서 우연히 개발한 우동과 짜장을 한 데 섞은 음식 우짜는 입맛 당기는 마력이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REPORT-news_r-00044-00001</td>\n",
       "      <td>조국(55) 전 법무부 장관을 기소한 검찰의 공소장이 공개되자 2017년 11월 아...</td>\n",
       "      <td>조 전 장관의 아들 조 씨가 대학원 입학 과정에서 특혜를 제공받았다는 의혹이 있는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REPORT-news_r-00105-00001</td>\n",
       "      <td>문재인 대통령은 2일 “새해에는 더욱 ‘확실한 변화’를 만들어내겠다”며 “권력기관...</td>\n",
       "      <td>어떠한 권력기관도 국민 위에 존재할 수 없다는 문 대통령의 발언은 검찰개혁 속도전의...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Id  \\\n",
       "0  REPORT-news_r-00014-00001   \n",
       "1  REPORT-news_r-00035-00001   \n",
       "2  REPORT-news_r-00042-00003   \n",
       "3  REPORT-news_r-00044-00001   \n",
       "4  REPORT-news_r-00105-00001   \n",
       "\n",
       "                                              source  \\\n",
       "0  일본 사법당국의 출국금지 명령이 내려져 있던 카를로스 곤(65) 전 르노닛산 회장이...   \n",
       "1  황교안 자유한국당 대표의 최측근인 김도읍 의원(재선)이 느닷없이 불출마를 선언하자 ...   \n",
       "2   추울수록 위력이 강할 듯했다.\\n   통영의 하루를 여는 음식이 시락국이라면 ‘우...   \n",
       "3  조국(55) 전 법무부 장관을 기소한 검찰의 공소장이 공개되자 2017년 11월 아...   \n",
       "4   문재인 대통령은 2일 “새해에는 더욱 ‘확실한 변화’를 만들어내겠다”며 “권력기관...   \n",
       "\n",
       "                                              target  \n",
       "0  출국금지 명령을 받은 곤 전 르노닛산 회장이 레바논으로 도주하며 일본의 정치적 박해...  \n",
       "1  황 대표는 김 의원의 불출마 소식을 알았다면 말릴 걸 알고 미리 말 안 한 것 같다...  \n",
       "2  통영에서 우연히 개발한 우동과 짜장을 한 데 섞은 음식 우짜는 입맛 당기는 마력이 ...  \n",
       "3  조 전 장관의 아들 조 씨가 대학원 입학 과정에서 특혜를 제공받았다는 의혹이 있는 ...  \n",
       "4  어떠한 권력기관도 국민 위에 존재할 수 없다는 문 대통령의 발언은 검찰개혁 속도전의...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975b51eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 06:56:56.419638: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-26 06:56:56.467429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 06:56:57.579484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "from datasets import Dataset\n",
    "\n",
    "# Dataset 형식으로 변환\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52608bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Id', 'source', 'target'],\n",
       "    num_rows: 146771\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a2f70b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Id', 'source', 'target'],\n",
       "    num_rows: 18300\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c031333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "# BART 토크나이저 및 모델 불러오기\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "058d8b66-29be-4d07-8dd2-2804a72d0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = model.config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411dac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch):\n",
    "    max_length = 512\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['source'], padding=\"max_length\", max_length=512, truncation=True)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], padding=\"max_length\", max_length=512, truncation=True)\n",
    "    \n",
    "    # EOS 토큰을 추가하기 전에 입력 및 목표 길이를 제한\n",
    "    input_ids = [raw_input[:max_length - 1] + [tokenizer.eos_token_id] for raw_input in input_encodings['input_ids']]\n",
    "    target_ids = [raw_target[:max_length - 1] + [tokenizer.eos_token_id] for raw_target in target_encodings['input_ids']]\n",
    "    \n",
    "    labels = torch.tensor(target_ids)\n",
    "    decoder_input_ids = shift_tokens_right(labels, model.config.pad_token_id, model.config.decoder_start_token_id)\n",
    "    labels[labels[:, :] == model.config.pad_token_id] = -100\n",
    "    encodings = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'decoder_input_ids': decoder_input_ids.tolist(),\n",
    "        'labels': labels.tolist(),\n",
    "    }\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a79f9e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466eb764ee444f15ad1666008f46d883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fa6cb00ee44ad9b0c002a7c1c5d008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋을 위에서 정의한 함수를 사용하여 변환\n",
    "train_dataset = train_dataset.map(convert_to_features, batched=True)\n",
    "test_dataset = test_dataset.map(convert_to_features, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "690b66a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Id', 'source', 'target', 'input_ids', 'attention_mask', 'decoder_input_ids', 'labels'],\n",
       "    num_rows: 146771\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33958086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Id', 'source', 'target', 'input_ids', 'attention_mask', 'decoder_input_ids', 'labels'],\n",
       "    num_rows: 18300\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a349ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 가능한지 확인하고 기본 장치로 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0422005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU instead.\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f00fd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 GPU로 이동\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8a2ab-fba6-4d24-97b4-89df0d05314d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9108c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 데이터셋의 형식 지정\n",
    "columns = ['input_ids', 'labels', 'decoder_input_ids', 'attention_mask']\n",
    "train_dataset.set_format(type='torch', columns=columns)\n",
    "test_dataset.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82a3446a-c69a-4abb-90d3-18a322470e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Id', 'source', 'target', 'input_ids', 'attention_mask', 'decoder_input_ids', 'labels'],\n",
       "    num_rows: 146771\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19f32605-e1e5-4c0b-b154-2836e162e5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Id', 'source', 'target', 'input_ids', 'attention_mask', 'decoder_input_ids', 'labels'],\n",
       "    num_rows: 18300\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a11c8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 인수 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/bart-summarizer',          \n",
    "    num_train_epochs=1,           \n",
    "    per_device_train_batch_size=2, \n",
    "    per_device_eval_batch_size=4,   \n",
    "    warmup_steps=500,               \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir='./logs',          \n",
    "    fp16=True,  # 추가: GPU 사용 시 mixed precision 학습 활성화\n",
    "    save_steps=1000,  # 체크포인트 저장 간격을 변경합니다. 이 값은 원하는 숫자로 조절할 수 있습니다.\n",
    "    save_total_limit=1,# 저장할 체크포인트 수를 제한합니다. 이 값은 원하는 숫자로 조절할 수 있습니다.\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy='steps',  # 추가: 평가 전략을 'steps'로 설정합니다.\n",
    "    save_strategy='steps',  # 추가: 저장 전략을 'steps'로 설정합니다.\n",
    "    eval_steps=1000,  # 추가: 평가 간격을 설정합니다. 이 값은 원하는 숫자로 조절할 수 있습니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63f163a4-c647-44f9-b4db-897e67dfba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rouge_score in ./.local/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./.local/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from rouge_score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in ./.local/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.10/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.local/lib/python3.10/site-packages (from nltk->rouge_score) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from nltk->rouge_score) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc36d6cf-6998-4dad-a68a-94e615601da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge 점수 계산을 위한 Scorer 생성\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    metric = load_metric(\"rouge\")\n",
    "\n",
    "    # 예측과 라벨 간 Rouge 점수 계산\n",
    "    scores = []\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        scores.append(scorer.score(pred, label))\n",
    "\n",
    "    # 평균 Rouge 점수 계산\n",
    "    final_scores = {key: 0 for key in ['rouge1', 'rouge2', 'rougeL']}\n",
    "    for score in scores:\n",
    "        for key in final_scores.keys():\n",
    "            final_scores[key] += score[key].fmeasure\n",
    "    final_scores = {key: value / len(scores) for key, value in final_scores.items()}\n",
    "\n",
    "    return final_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16fbbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이너 인스턴스 생성\n",
    "trainer = Trainer(\n",
    "    model=model,                       \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,        \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "927a7a5b-a865-491e-85ff-dc9202e2545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1001' max='73386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1001/73386 03:17 < 3:58:07, 5.07 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='4575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  12/4575 00:01 < 11:57, 6.36 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.98 GiB (GPU 0; 9.50 GiB total capacity; 4.47 GiB already allocated; 2.82 GiB free; 5.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 훈련 시작\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2006\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2003\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2004\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2006\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2287\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2285\u001b[0m             metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2287\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2993\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2990\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2992\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2993\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3001\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3003\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3201\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3200\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[0;32m-> 3201\u001b[0m     preds_host \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;28;01mif\u001b[39;00m preds_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_prediction_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   3204\u001b[0m \u001b[38;5;66;03m# Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:114\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m    111\u001b[0m     new_tensors\n\u001b[1;32m    112\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:114\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[1;32m    111\u001b[0m     new_tensors\n\u001b[1;32m    112\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:116\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    119\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    120\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:75\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     72\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m     78\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.98 GiB (GPU 0; 9.50 GiB total capacity; 4.47 GiB already allocated; 2.82 GiB free; 5.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 모델 훈련 시작\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c70ff6-c4a8-49bb-8353-092f1475bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "yhat = trainer.predict(test_dataset)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb2d27-805d-4cb3-a78d-e93b402cd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'eval_loss': 0.4558240473270416, 'eval_runtime': 1799.2075, 'eval_samples_per_second': 10.171, 'eval_steps_per_second': 10.171}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "316d2020-7720-4de2-b7d3-b4077fe15c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a247d0db-5979-4334-ab95-838b14b9804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Wed Apr 26 07:05:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:CA:00.0 Off |                   On |\n",
      "| N/A   29C    P0    42W / 300W |                  N/A |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0    7   0   0  |      6MiB /  9728MiB | 14      0 |  1   0    0    0    0 |\n",
      "|                  |      0MiB / 16383MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e1f2ad9-9e0d-4471-8469-950223292465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "261af080-1b51-4905-8487-7abdd0297c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf3ccb606ad45aebfb5ec1de23ec216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/146771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.save_to_disk(\"train_dataset_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68b7743c-81a0-4e50-8957-73a4c7250c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f6da40bda740b8b51bdcd6ca79f1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/18300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset.save_to_disk(\"test_dataset_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff9c26f5-f1be-4465-887a-e8cb5068c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         100G   11G   90G  11% /\n",
      "/dev/sda4       860G   30G  830G   4% /rt\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           101G  5.5M  101G   1% /etc/hosts\n",
      "shm             4.0G  4.0K  4.0G   1% /dev/shm\n",
      "/dev/loop0      100G   11G   90G  11% /mnt/elice/shared\n",
      "tmpfs           504G   12K  504G   1% /proc/driver/nvidia\n",
      "overlay         100G   11G   90G  11% /usr/lib/x86_64-linux-gnu/libcuda.so.520.61.05\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edc6f4-7b5f-4bbf-8b35-fa227ccf620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, dataset_name):\n",
    "    for feature in dataset.column_names:\n",
    "        # 문자열 특성이 있는 경우 별도로 처리\n",
    "        if isinstance(dataset[feature][0], str):\n",
    "            with open(f\"{dataset_name}_{feature}.txt\", \"w\") as f:\n",
    "                for item in dataset[feature]:\n",
    "                    f.write(f\"{item}\\n\")\n",
    "        else:\n",
    "            feature_tensor = torch.tensor(dataset[feature])\n",
    "            torch.save(feature_tensor, f\"{dataset_name}_{feature}.pt\")\n",
    "\n",
    "# train_dataset과 test_dataset 저장\n",
    "save_dataset(train_dataset, \"train_dataset\")\n",
    "save_dataset(test_dataset, \"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfaa40d-314a-479b-9644-15771d5d9c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
